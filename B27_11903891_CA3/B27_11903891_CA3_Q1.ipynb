{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47b4486",
   "metadata": {},
   "source": [
    "KEERTHIVASAN 11903891\n",
    "\n",
    "MACHINE LEARNING \n",
    "\n",
    "\"__IMAGE CLASSIFICATION MODEL USING CONVOLUTIONAL NEURAL NETWORK__\"\n",
    "\n",
    "CLASSIFYING __BIKE__ OR __CAR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eab8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef2657",
   "metadata": {},
   "source": [
    "Here I used Sequential flow model,\n",
    "\n",
    "1 __conv2d__ layer,\n",
    "\n",
    "1 __maxpooling player__ of kernal size 2x2\n",
    "\n",
    "1 __flattening layer__ to serialze layer's output\n",
    "\n",
    "1 __Dense layer__, output layer with units 1 ( __binary classification 1- car, 0 -bike,__ activation function is sigmoid since the output layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a0dd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "                (3, 3),\n",
    "                input_shape=(64, 64, 3),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128,\n",
    "                activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72257e78",
   "metadata": {},
   "source": [
    "I'm using __image Generator__ to get different no of scales, zoom, cropped images from set of input images here i'm using 10 training images, but image generator outputs 8 batch of images in various version.\n",
    "\n",
    "The image generator because the upload file size is of 5mb in ums\n",
    "\n",
    "__Image loading and pre-processing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd8918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                         shear_range=0.2,\n",
    "                                         zoom_range=0.2,\n",
    "                                         horizontal_flip=True)\n",
    "\n",
    "validate_data_generator = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64125f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_data_generator.flow_from_directory(f\"CA_3_bike_car_dataset//train\",\n",
    "                                                       target_size=(64, 64),\n",
    "                                                       batch_size=8,\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "validation_set = validate_data_generator.flow_from_directory(f\"CA_3_bike_car_dataset//validate\",\n",
    "                                                            target_size=(64, 64),\n",
    "                                                            batch_size=8,\n",
    "                                                            class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41290b12",
   "metadata": {},
   "source": [
    "__TRAINING THE CONV MODEL__\n",
    "\n",
    "of 20 epochs/cycle of same training dataset with batch folding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b50de39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4660 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sskva\\AppData\\Local\\Temp\\ipykernel_49592\\2037898728.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 382ms/step - loss: 0.4977 - accuracy: 0.6667 - val_loss: 0.7715 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 0.4301 - accuracy: 0.8333 - val_loss: 0.8272 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 0.4845 - accuracy: 0.8333 - val_loss: 0.8281 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 266ms/step - loss: 0.4317 - accuracy: 0.7500 - val_loss: 0.8012 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 278ms/step - loss: 0.4733 - accuracy: 0.6667 - val_loss: 0.9313 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 263ms/step - loss: 0.3958 - accuracy: 0.8333 - val_loss: 0.8062 - val_accuracy: 0.6000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 0.2747 - accuracy: 0.9167 - val_loss: 0.7787 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.2887 - accuracy: 0.9167 - val_loss: 0.8004 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 0.2630 - accuracy: 0.9167 - val_loss: 0.8008 - val_accuracy: 0.6000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 0.2396 - accuracy: 0.9167 - val_loss: 0.8358 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.2551 - accuracy: 0.9167 - val_loss: 0.8217 - val_accuracy: 0.6000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 0.1923 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 0.2068 - accuracy: 0.9167 - val_loss: 0.8540 - val_accuracy: 0.6000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 0.1867 - accuracy: 0.9167 - val_loss: 0.8810 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.1696 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.6000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.1397 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.7000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 238ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.9156 - val_accuracy: 0.7000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.6000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1427e7d3700>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set, \n",
    "         steps_per_epoch=2,\n",
    "             epochs=20,\n",
    "         validation_data= validation_set,\n",
    "         validation_steps=2\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf0690",
   "metadata": {},
   "source": [
    "OS library for file system handling\n",
    "\n",
    "keras.preprocessing.image is for image handling\n",
    "\n",
    "I'm using expand_dims from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "462bc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04b6f373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CA_3_bike_car_dataset\\\\test\\\\car_10.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\car_15.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\car_18.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\car_19.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\car_9.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_11.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_16.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_17.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_18.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_8.jpeg',\n",
       " 'CA_3_bike_car_dataset\\\\test\\\\motorbike_9.jpeg']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = []\n",
    "\n",
    "for root, dir_name, files in os.walk('CA_3_bike_car_dataset\\\\test'):\n",
    "    for file in files:\n",
    "        if \".jpeg\" in file:\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "    \n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f87d2678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      ">Predicted label: Car\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ">Predicted label: Car\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ">Predicted label: Bike\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for img in image_paths:\n",
    "    img_name = img\n",
    "    timg = image.image_utils.load_img(img_name,\n",
    "                                       target_size=(64, 64))\n",
    "    timg = image.image_utils.img_to_array(timg)\n",
    "    \n",
    "    timg = np.expand_dims(timg, axis=0)\n",
    "    \n",
    "    result = model.predict(timg)\n",
    "    \n",
    "    if result[0][0] == 1:\n",
    "        print(\">Predicted label: Car\")\n",
    "    else:\n",
    "        print(\">Predicted label: Bike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e516f19a",
   "metadata": {},
   "source": [
    "5 images are misclassified, the accuracy can be imporved by appending more hidden layer conv, maxpooling and dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57905255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
